{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete after - My Github Access Token 6c34ca060aa8404b59b8af8b876f7c1c975f4f2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1cDMWdOjJ2r"
   },
   "source": [
    "This notebook (and the slides from lecture 8) will help you go straight from training a model in Colab to deploying it in a webpage with TensorFlow.js - without having to leave the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "248xIjNGCRU0"
   },
   "source": [
    "Configure this notebook to work with your GitHub account by populating these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ft9uEY7UCH46"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "g4k9_Ke9CaOq"
   },
   "outputs": [],
   "source": [
    "# your github username\n",
    "USER_NAME = \"UPDATE_ME\" \n",
    "\n",
    "# the email associated with your commits\n",
    "# (may not matter if you leave it as this)\n",
    "USER_EMAIL = \"foo@bar.com\" \n",
    "\n",
    "# the user token you've created (see the lecture 8 slides for instructions)\n",
    "TOKEN = \"UPDATE_ME\" \n",
    "\n",
    "# site name\n",
    "# for example, if my user_name is \"foo\", then this notebook will create\n",
    "# a site at https://foo.github.io/hw4/\n",
    "SITE_NAME = \"hw4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnPqmO8vDDwW"
   },
   "source": [
    "Next, run this cell to configure git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Q0IMoqVdCIb4"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email {USER_NAME}\n",
    "!git config --global user.name  {USER_EMAIL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYfDxuMfDVas"
   },
   "source": [
    "Clone your GitHub pages repo (see the lecture 8 slides for instructions on how to create one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qRUyZiFqDUxt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "repo_path = USER_NAME + '.github.io'\n",
    "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
    "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qu4OA27iDU0e"
   },
   "outputs": [],
   "source": [
    "os.chdir(repo_path)\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KgISB_cAHPIs"
   },
   "source": [
    "Create a folder for your site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UAA6t4slF0nB"
   },
   "outputs": [],
   "source": [
    "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
    "if not os.path.exists(project_path): \n",
    "  os.mkdir(project_path)\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwYh8sXKHs3O"
   },
   "source": [
    "These paths will be used by the converter script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ABggwdWMGe2h"
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "  os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJpu2BkSUWe4"
   },
   "source": [
    "As an example, we will create and vectorize a few documents. (Check out https://www.gutenberg.org/ for a bunch of free e-books.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Pgm8y7fWHxOI"
   },
   "outputs": [],
   "source": [
    "# A few snippets from Alice in Wonderland\n",
    "ex1 = \"Alice was beginning to get very tired of sitting by her sister on the bank.\"\n",
    "ex2 = \"Once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it.\"\n",
    "\n",
    "# Dracula\n",
    "ex3 = \"Buda-Pesth seems a wonderful place.\"\n",
    "ex4 = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
    "\n",
    "# Illiad\n",
    "ex5 = \"Scepticism was as much the result of knowledge, as knowledge is of scepticism.\"\n",
    "ex6 = \"To be content with what we at present know, is, for the most part, to shut our ears against conviction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CASpAIgJalTp"
   },
   "outputs": [],
   "source": [
    "x_train = [ex1, ex2, ex3, ex4, ex5, ex6]\n",
    "y_train = [0, 0, 1, 1, 2, 2] # Indicating which book each sentence is from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVfStwZCYBAq"
   },
   "source": [
    "Tokenize the documents, create a word index (word -> number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HOHTxREVQalF"
   },
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "num_words = 1000\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# Fit the tokenizer on the training data\n",
    "t = Tokenizer(num_words=num_words)\n",
    "t.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mqyqHuLwWT-Z"
   },
   "outputs": [],
   "source": [
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "feIAyrrxYFoU"
   },
   "source": [
    "Here's how we vectorize a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Jfi7tJbHTwIc"
   },
   "outputs": [],
   "source": [
    "vectorized = t.texts_to_sequences([ex1])\n",
    "print(vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUfL6MVhYHof"
   },
   "source": [
    "Apply padding if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rbghRbY5QaMV"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9xwd6ND_UIKk"
   },
   "outputs": [],
   "source": [
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9NUXTTuYLZ0"
   },
   "source": [
    "We will save the word index in metadata. Later, we'll use it to convert words typed in the browser to numbers for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UpzusXHhULBr"
   },
   "outputs": [],
   "source": [
    "metadata = {\n",
    "  'word_index': t.word_index,\n",
    "  'max_len': max_len,\n",
    "  'vocabulary_size': num_words,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l57eA3ApZGsC"
   },
   "source": [
    "Define a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oLQeTh3uVqtj"
   },
   "outputs": [],
   "source": [
    "embedding_size = 8\n",
    "n_classes = 3\n",
    "epochs = 10\n",
    "\n",
    "import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VOtCRJiYWZZ"
   },
   "source": [
    "Prepare some training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-Q8Y1ZuZYYKC"
   },
   "outputs": [],
   "source": [
    "x_train = t.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VUWlD3jiX10c"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1YbPNWIenE5"
   },
   "source": [
    "Demo using the model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KcmpKvKUY_hK"
   },
   "outputs": [],
   "source": [
    "test_example = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
    "x_test = t.texts_to_sequences([test_example])\n",
    "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y9dsZSQnrqoU"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)\n",
    "print(preds)\n",
    "import numpy as np\n",
    "print(np.argmax(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-Kuwvqcfptq"
   },
   "source": [
    "Convert the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nyo2Q_ehe2RT"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
    "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
    "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
    "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z609mw1aj-RJ"
   },
   "source": [
    "Write an index.html and an index.js file configured to load our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IoFAxt8nj9fp"
   },
   "outputs": [],
   "source": [
    "index_html = \"\"\"\n",
    "<!doctype html>\n",
    "\n",
    "<body>\n",
    "  <style>\n",
    "    #textfield {\n",
    "      font-size: 120%;\n",
    "      width: 60%;\n",
    "      height: 200px;\n",
    "    }\n",
    "  </style>\n",
    "  <h1>\n",
    "    Title\n",
    "  </h1>\n",
    "  <hr>\n",
    "  <div class=\"create-model\">\n",
    "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
    "  </div>\n",
    "  <div>\n",
    "    <div>\n",
    "      <span>Vocabulary size: </span>\n",
    "      <span id=\"vocabularySize\"></span>\n",
    "    </div>\n",
    "    <div>\n",
    "      <span>Max length: </span>\n",
    "      <span id=\"maxLen\"></span>\n",
    "    </div>\n",
    "  </div>\n",
    "  <hr>\n",
    "  <div>\n",
    "    <select id=\"example-select\" class=\"form-control\">\n",
    "      <option value=\"example1\">Alice's Adventures in Wonderland</option>\n",
    "      <option value=\"example2\">Dracula</option>\n",
    "      <option value=\"example3\">The Iliad</option>\n",
    "    </select>\n",
    "  </div>\n",
    "  <div>\n",
    "    <textarea id=\"text-entry\"></textarea>\n",
    "  </div>\n",
    "  <hr>\n",
    "  <div>\n",
    "    <span id=\"status\">Standing by.</span>\n",
    "  </div>\n",
    "\n",
    "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
    "  <script src='index.js'></script>\n",
    "</body>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-JsQLbLnkhhk"
   },
   "outputs": [],
   "source": [
    "index_js = \"\"\"\n",
    "const HOSTED_URLS = {\n",
    "  model:\n",
    "      'model_js/model.json',\n",
    "  metadata:\n",
    "      'model_js/metadata.json'\n",
    "};\n",
    "\n",
    "const examples = {\n",
    "  'example1':\n",
    "      'Alice was beginning to get very tired of sitting by her sister on the bank.',\n",
    "  'example2':\n",
    "      'Buda-Pesth seems a wonderful place.',\n",
    "  'example3':\n",
    "      'Scepticism was as much the result of knowledge, as knowledge is of scepticism.'      \n",
    "};\n",
    "\n",
    "function status(statusText) {\n",
    "  console.log(statusText);\n",
    "  document.getElementById('status').textContent = statusText;\n",
    "}\n",
    "\n",
    "function showMetadata(metadataJSON) {\n",
    "  document.getElementById('vocabularySize').textContent =\n",
    "      metadataJSON['vocabulary_size'];\n",
    "  document.getElementById('maxLen').textContent =\n",
    "      metadataJSON['max_len'];\n",
    "}\n",
    "\n",
    "function settextField(text, predict) {\n",
    "  const textField = document.getElementById('text-entry');\n",
    "  textField.value = text;\n",
    "  doPredict(predict);\n",
    "}\n",
    "\n",
    "function setPredictFunction(predict) {\n",
    "  const textField = document.getElementById('text-entry');\n",
    "  textField.addEventListener('input', () => doPredict(predict));\n",
    "}\n",
    "\n",
    "function disableLoadModelButtons() {\n",
    "  document.getElementById('load-model').style.display = 'none';\n",
    "}\n",
    "\n",
    "function doPredict(predict) {\n",
    "  const textField = document.getElementById('text-entry');\n",
    "  const result = predict(textField.value);\n",
    "  score_string = \"Class scores: \";\n",
    "  for (var x in result.score) {\n",
    "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
    "  }\n",
    "  //console.log(score_string);\n",
    "  status(\n",
    "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
    "}\n",
    "\n",
    "function prepUI(predict) {\n",
    "  setPredictFunction(predict);\n",
    "  const testExampleSelect = document.getElementById('example-select');\n",
    "  testExampleSelect.addEventListener('change', () => {\n",
    "    settextField(examples[testExampleSelect.value], predict);\n",
    "  });\n",
    "  settextField(examples['example1'], predict);\n",
    "}\n",
    "\n",
    "async function urlExists(url) {\n",
    "  status('Testing url ' + url);\n",
    "  try {\n",
    "    const response = await fetch(url, {method: 'HEAD'});\n",
    "    return response.ok;\n",
    "  } catch (err) {\n",
    "    return false;\n",
    "  }\n",
    "}\n",
    "\n",
    "async function loadHostedPretrainedModel(url) {\n",
    "  status('Loading pretrained model from ' + url);\n",
    "  try {\n",
    "    const model = await tf.loadModel(url);\n",
    "    status('Done loading pretrained model.');\n",
    "    disableLoadModelButtons();\n",
    "    return model;\n",
    "  } catch (err) {\n",
    "    console.error(err);\n",
    "    status('Loading pretrained model failed.');\n",
    "  }\n",
    "}\n",
    "\n",
    "async function loadHostedMetadata(url) {\n",
    "  status('Loading metadata from ' + url);\n",
    "  try {\n",
    "    const metadataJson = await fetch(url);\n",
    "    const metadata = await metadataJson.json();\n",
    "    status('Done loading metadata.');\n",
    "    return metadata;\n",
    "  } catch (err) {\n",
    "    console.error(err);\n",
    "    status('Loading metadata failed.');\n",
    "  }\n",
    "}\n",
    "\n",
    "class Classifier {\n",
    "\n",
    "  async init(urls) {\n",
    "    this.urls = urls;\n",
    "    this.model = await loadHostedPretrainedModel(urls.model);\n",
    "    await this.loadMetadata();\n",
    "    return this;\n",
    "  }\n",
    "\n",
    "  async loadMetadata() {\n",
    "    const metadata =\n",
    "        await loadHostedMetadata(this.urls.metadata);\n",
    "    showMetadata(metadata);\n",
    "    this.maxLen = metadata['max_len'];\n",
    "    console.log('maxLen = ' + this.maxLen);\n",
    "    this.wordIndex = metadata['word_index']\n",
    "  }\n",
    "\n",
    "  predict(text) {\n",
    "    // Convert to lower case and remove all punctuations.\n",
    "    const inputText =\n",
    "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
    "    // Look up word indices.\n",
    "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
    "    for (let i = 0; i < inputText.length; ++i) {\n",
    "      const word = inputText[i];\n",
    "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
    "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
    "    }\n",
    "    const input = inputBuffer.toTensor();\n",
    "    //console.log(input);\n",
    "\n",
    "    status('Running inference');\n",
    "    const beginMs = performance.now();\n",
    "    const predictOut = this.model.predict(input);\n",
    "    //console.log(predictOut.dataSync());\n",
    "    const score = predictOut.dataSync();//[0];\n",
    "    predictOut.dispose();\n",
    "    const endMs = performance.now();\n",
    "\n",
    "    return {score: score, elapsed: (endMs - beginMs)};\n",
    "  }\n",
    "};\n",
    "\n",
    "async function setup() {\n",
    "  if (await urlExists(HOSTED_URLS.model)) {\n",
    "    status('Model available: ' + HOSTED_URLS.model);\n",
    "    const button = document.getElementById('load-model');\n",
    "    button.addEventListener('click', async () => {\n",
    "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
    "      prepUI(x => predictor.predict(x));\n",
    "    });\n",
    "    button.style.display = 'inline-block';\n",
    "  }\n",
    "\n",
    "  status('Standing by.');\n",
    "}\n",
    "\n",
    "setup();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KbvVVh1rkmga"
   },
   "outputs": [],
   "source": [
    "with open('index.html','w') as f:\n",
    "  f.write(index_html)\n",
    "  \n",
    "with open('index.js','w') as f:\n",
    "  f.write(index_js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0YtvaoazkuRT"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3NX9FVLiBO7"
   },
   "source": [
    "Commit and push everything. Note: we're storing large binary files in GitHub, this isn't ideal (if you want to deploy a model down the road, better to host it in a cloud storage bucket)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RoL5aoRUh5DB"
   },
   "outputs": [],
   "source": [
    "!git add . \n",
    "!git commit -m \"colab -> github\"\n",
    "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io/ master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDoo_fDVic2E"
   },
   "source": [
    "All done! Hopefully everything worked. You may need to wait a few moments for the changes to appear in your site. If not working, check the JavaScript console for errors (in Chrome: View -> Developer -> JavaScript Console)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1V1QLCxlikOI"
   },
   "outputs": [],
   "source": [
    "print(\"Now, visit https://%s.github.io/%s/\" % (USER_NAME, SITE_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnN6zAHWqPnR"
   },
   "source": [
    "If you are debugging and Chrome is failing to pick up your changes, though you've verified they're present in your GitHub repo, see the second answer to: https://superuser.com/questions/89809/how-to-force-refresh-without-cache-in-google-chrome"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8_colab_to_webpage.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
